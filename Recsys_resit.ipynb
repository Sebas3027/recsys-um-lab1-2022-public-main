{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender Systems - Repair Project Component - Group 8\n",
    "Sebas van Sluijsdam\n",
    "i6252182\n",
    "\n",
    "Assignment:\n",
    "Your evaluation should answer the following research question: Are there any differences in the performances of a group recommender using the average satisfaction strategy related to the size of the groups?\n",
    "\n",
    "To answer this research question you should perform an offline evaluation following the pipeline shown in lab 2 - you can find the slides of the pipeline on the Group Recommenders lecture on Canvas.\n",
    "\n",
    " \n",
    "\n",
    "Consider the following additional instructions:\n",
    "\n",
    "1.       You must use the dataset provided for tutorial 1 ( https://github.com/barnap/recsys-um-lab1-2022-public ). It contains information about the evaluation of users for certain movies, and the subtitles of such movies.\n",
    "\n",
    "2.       Focus only on random groups of size 2, 3 and 5; you have to implement the generation of random groups of size 2, 3, and 5 from your dataset.\n",
    "\n",
    "3.       You must use an Hold-out validation strategy (80% for the training, 20% for the test set).\n",
    "\n",
    "4.       As showed in the tutorial 1, you can train both a CF strategy and a CB strategy with the given datasets. Choose one of the two strategies proposed in the tutorial 1, for providing individual recommendations for the group members. You can adapt the source code provided in the tutorial for this.\n",
    "\n",
    "5.       The group aggregation strategy to evaluate is the “average satisfaction”.\n",
    "\n",
    "6.       Use a decoupled evaluation setting and the nDCG metric for your evaluation (consider recommendation lists of 5 items)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the datasets into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>216</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964981208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0     1     1     4.0  964982703\n",
       "1     1     3     4.0  964981247\n",
       "2     1     6     4.0  964982224\n",
       "3     1    70     3.0  964982400\n",
       "4     1   101     5.0  964980868\n",
       "5     1   110     4.0  964982176\n",
       "6     1   151     5.0  964984041\n",
       "7     1   157     5.0  964984100\n",
       "8     1   163     5.0  964983650\n",
       "9     1   216     5.0  964981208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>genres</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toy story</td>\n",
       "      <td>1995</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>In a world where toys are living things who pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jumanji</td>\n",
       "      <td>1995</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>In 1869, near Brantford, New Hampshire, two br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grumpier old men</td>\n",
       "      <td>1995</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>The feud between Max (Walter Matthau) and John...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waiting to exhale</td>\n",
       "      <td>1995</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>\"Friends are the People who let you be yoursel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>father of the bride part ii</td>\n",
       "      <td>1995</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>The film begins five years after the events of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>heat</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>Neil McCauley, a career criminal, hires Waingr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sabrina</td>\n",
       "      <td>1995</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>Sabrina Fairchild is the young daughter of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tom and huck</td>\n",
       "      <td>1995</td>\n",
       "      <td>Adventure|Children</td>\n",
       "      <td>The movie opens with Injun Joe (Eric Schweig) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sudden death</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action</td>\n",
       "      <td>Darren McCord (Jean-Claude Van Damme) is a Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>goldeneye</td>\n",
       "      <td>1995</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>In 1986, at Arkhangelsk, MI6 agents James Bond...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  year  \\\n",
       "item                                      \n",
       "1                       toy story  1995   \n",
       "2                         jumanji  1995   \n",
       "3                grumpier old men  1995   \n",
       "4               waiting to exhale  1995   \n",
       "5     father of the bride part ii  1995   \n",
       "6                            heat  1995   \n",
       "7                         sabrina  1995   \n",
       "8                    tom and huck  1995   \n",
       "9                    sudden death  1995   \n",
       "10                      goldeneye  1995   \n",
       "\n",
       "                                           genres  \\\n",
       "item                                                \n",
       "1     Adventure|Animation|Children|Comedy|Fantasy   \n",
       "2                      Adventure|Children|Fantasy   \n",
       "3                                  Comedy|Romance   \n",
       "4                            Comedy|Drama|Romance   \n",
       "5                                          Comedy   \n",
       "6                           Action|Crime|Thriller   \n",
       "7                                  Comedy|Romance   \n",
       "8                              Adventure|Children   \n",
       "9                                          Action   \n",
       "10                      Action|Adventure|Thriller   \n",
       "\n",
       "                                                   plot  \n",
       "item                                                     \n",
       "1     In a world where toys are living things who pr...  \n",
       "2     In 1869, near Brantford, New Hampshire, two br...  \n",
       "3     The feud between Max (Walter Matthau) and John...  \n",
       "4     \"Friends are the People who let you be yoursel...  \n",
       "5     The film begins five years after the events of...  \n",
       "6     Neil McCauley, a career criminal, hires Waingr...  \n",
       "7     Sabrina Fairchild is the young daughter of the...  \n",
       "8     The movie opens with Injun Joe (Eric Schweig) ...  \n",
       "9     Darren McCord (Jean-Claude Van Damme) is a Fre...  \n",
       "10    In 1986, at Arkhangelsk, MI6 agents James Bond...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "\n",
    "movies_path = 'preprocessed_dataset/movies.csv'\n",
    "ratings_path = 'preprocessed_dataset/ratings.csv'\n",
    "\n",
    "\n",
    "ratings_df = pd.read_csv(ratings_path) \n",
    "display(ratings_df.head(10))\n",
    "\n",
    "movies_df = pd.read_csv(movies_path, index_col=\"item\")\n",
    "display(movies_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create all necessary functions to perform the group creation and the hold-out validation (with a 80:20 ratio) to create a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a group into a train and test set\n",
    "def split_users(user_range, ratio=0.8):\n",
    "    user_ids = list(range(user_range[0], user_range[1] + 1))\n",
    "    random.shuffle(user_ids)\n",
    "    split_index = int(len(user_ids) * ratio)\n",
    "    train_set = user_ids[:split_index]\n",
    "    test_set = user_ids[split_index:]\n",
    "    return train_set, test_set\n",
    "\n",
    "# Function to generate group of a given size\n",
    "def generate_groups(user_ids,size):\n",
    "\n",
    "    # Split the list into groups of the specified size\n",
    "    groups = [user_ids[i:i + size] for i in range(0, len(user_ids), size) if len(user_ids[i:i + size]) == size]\n",
    "\n",
    "    return groups\n",
    "\n",
    "# Retrieve the user-item interactions for all users in the group\n",
    "def user_item_interactions(df,groups):\n",
    "\n",
    "    all_interactions = pd.DataFrame()\n",
    "    try:\n",
    "        for group in groups:\n",
    "            group_interactions = df[df['user'].isin(group)]\n",
    "            all_interactions = pd.concat([all_interactions, group_interactions])\n",
    "    except TypeError:\n",
    "        all_interactions = df[df['user'].isin(groups)]\n",
    "\n",
    "    return all_interactions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use these functions to create our synthethic groups and train/test split.\n",
    "We first create a train/test split, and afterwards we create the groups. We do this to ensure that all users in a group are either in the train or test data and never in both.\n",
    "This ensures that that if one member of a group is in the test set, then all are, and they all have the same pool of items for which predictions need to be made.\n",
    "Because we create groups of random size, we are not concerned in preserving existing user relationships or characteristics within a group. Making this a viable strategy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train groups of size 2: 244\n",
      "Example train groups: [[9, 211], [204, 391], [544, 385], [303, 484], [494, 65]]\n",
      "Number of test groups of size 2: 61\n",
      "Example test groups: [[378, 252], [270, 326], [243, 471], [319, 8], [485, 294]]\n"
     ]
    }
   ],
   "source": [
    "# Split users into train and test sets\n",
    "train_users, test_users = split_users((1, 610))\n",
    "\n",
    "# Generate groups from train and test sets\n",
    "train_groups2 = generate_groups(train_users, 2)\n",
    "test_groups2 = generate_groups(test_users, 2)\n",
    "\n",
    "train_groups3 = generate_groups(train_users, 3)\n",
    "test_groups3 = generate_groups(test_users, 3)\n",
    "\n",
    "train_groups5 = generate_groups(train_users, 5)\n",
    "test_groups5 = generate_groups(test_users, 5)\n",
    "\n",
    "# Example: Print the number of groups and first 5 groups for each size\n",
    "print(f\"Number of train groups of size 2: {len(train_groups2)}\")\n",
    "print(\"Example train groups:\", train_groups2[:5])\n",
    "\n",
    "print(f\"Number of test groups of size 2: {len(test_groups2)}\")\n",
    "print(\"Example test groups:\", test_groups2[:5])\n",
    "\n",
    "# Create dataframes of the test split in user-item interactions \n",
    "train_set = user_item_interactions(ratings_df,train_users)  \n",
    "test_i2 = user_item_interactions(ratings_df,test_groups2)\n",
    "\n",
    "test_i3 = user_item_interactions(ratings_df,test_groups3)\n",
    "\n",
    "test_i5 = user_item_interactions(ratings_df,test_groups5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the train and test sets we can start to train a Collaborative filtering algorithm, using User-User Nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lenskit.algorithms.ranking.TopN at 0x25a79d13e80>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Source code from Tutorial Lab 1.ipynb:\n",
    "from lenskit.algorithms import Recommender\n",
    "from lenskit.algorithms import Predictor\n",
    "from lenskit.algorithms.user_knn import UserUser\n",
    "\n",
    "# We use the collaborative user algorithm UserUser, that use the nearest neighbors \n",
    "user_user = UserUser(15, min_nbrs=3)  # Minimum (3) and maximum (15) number of neighbors to consider\n",
    "# Train the model\n",
    "recsys = Recommender.adapt(user_user)\n",
    "recsys.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now search for the items we want to create predictions for. We do this by getting 10% of the total amount of items, both generic items and tail items. Recommending a mix of generic and tail items can balance user engagement. Users may appreciate recommendations of familiar items (generic) while also being exposed to new and exciting options (tail), which can keep them engaged with your platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amount of items with more than 1 rating: 2305'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356, 592, 648, 1704, 10]\n"
     ]
    }
   ],
   "source": [
    "#Sort on the counts each item has been given a rating\n",
    "count_ratings_df = ratings_df[['user', 'item']].groupby(['item']).filter(lambda x: len(x) > 4).groupby(['item']).count()\n",
    "count_ratings_df = count_ratings_df.sort_values(by='user', ascending=False)\n",
    "amount_items = len(count_ratings_df)\n",
    "display(f\"Amount of items with more than 1 rating: {amount_items}\")\n",
    "\n",
    "start_index = 0\n",
    "skip_interval = 10\n",
    "\n",
    "# Initialize an empty list to store the selected items\n",
    "selected_items = []\n",
    "\n",
    "while start_index < len(count_ratings_df):\n",
    "    # Retrieve the selected item\n",
    "    selected_item = count_ratings_df.index[start_index]\n",
    "\n",
    "    # Append the selected item to the list\n",
    "    selected_items.append(selected_item)\n",
    "\n",
    "    # Increment the start index by the skip interval to get the next item\n",
    "    start_index += skip_interval\n",
    "\n",
    "# Convert the list of selected items to a DataFrame\n",
    "\n",
    "# Display the selected items\n",
    "print(selected_items[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a list of all items we want to make a prediction for, so now we can start making the predictions for all 3 group sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of our predictions: \n",
      "          item  predicted_rating  user\n",
      "0         356          4.868218   252\n",
      "1         592          3.840692   252\n",
      "2         648          4.176156   252\n",
      "3        1704          4.578722   252\n",
      "4          10          4.163091   252\n",
      "...       ...               ...   ...\n",
      "28177  102033          3.530410   369\n",
      "28178  104243          2.860146   369\n",
      "28179    3871               NaN   369\n",
      "28180   93272          2.704089   369\n",
      "28181    1785          3.870222   369\n",
      "\n",
      "[28182 rows x 3 columns] \n"
     ]
    }
   ],
   "source": [
    "def predict_ratings( item_ids,interactions_df):\n",
    "    all_predictions = []\n",
    "    # Loop through all users\n",
    "    for user_id in interactions_df['user'].unique():\n",
    "        user_interactions = interactions_df[interactions_df['user'] == user_id]\n",
    "\n",
    "        # Convert to pandas Series with item as index and rating as values\n",
    "        user_ratings = user_interactions.set_index('item')['rating']\n",
    "\n",
    "        # Predict ratings using the recommender system\n",
    "        # Add predictions to a df\n",
    "        predicted_ratings = recsys.predict_for_user(user_id, item_ids, ratings=user_ratings)\n",
    "        predictions_df = predicted_ratings.to_frame(name='predicted_rating').reset_index()\n",
    "        predictions_df['user'] = user_id\n",
    "        all_predictions.append(predictions_df)\n",
    "\n",
    "    return pd.concat(all_predictions, ignore_index=True)\n",
    "# Make the predictions\n",
    "predicted_ratings2 = predict_ratings(selected_items, test_i2)\n",
    "predicted_ratings3 = predict_ratings(selected_items, test_i3)\n",
    "predicted_ratings5 = predict_ratings(selected_items, test_i5)\n",
    "print(f\"First 5 rows of our predictions: \\n { predicted_ratings2[:5]} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to do a group aggregation with average satisfaction, considering recommendation lists of 5 items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [2261, 2730, 3030, 5500, 106766], 1: [3030, 3983, 356, 1096, 750], 2: [3030, 1103, 5500, 104879, 1096], 3: [1931, 5500, 1921, 750, 3030], 4: [750, 356, 3030, 1611, 1103], 5: [356, 2261, 5500, 1103, 750], 6: [3030, 5500, 104879, 3983, 933], 7: [3030, 3983, 750, 1274, 1921], 8: [750, 1274, 933, 356, 4011], 9: [750, 5500, 918, 1288, 1921], 10: [3030, 5339, 93272, 1921, 933], 11: [3030, 3983, 104879, 2261, 1096], 12: [501, 750, 5500, 55442, 97304], 13: [356, 5500, 1096, 2730, 3030], 14: [1096, 918, 3030, 3983, 1103], 15: [1096, 356, 1967, 5500, 1921], 16: [1096, 918, 1288, 3030, 1266], 17: [1096, 3030, 3983, 5500, 1103], 18: [194, 933, 3983, 2730, 98961], 19: [3030, 5500, 918, 104879, 933], 20: [5500, 1103, 1096, 933, 750], 21: [3030, 949, 3983, 1096, 501], 22: [3030, 1096, 3983, 750, 55442], 23: [3030, 3983, 750, 1103, 1704], 24: [3030, 5500, 1967, 933, 104879], 25: [3983, 1785, 933, 1103, 5500], 26: [750, 1274, 918, 1096, 356], 27: [1096, 1921, 933, 750, 1266], 28: [3030, 1096, 918, 750, 3983], 29: [1096, 2730, 5500, 1103, 356], 30: [3030, 3983, 5500, 4011, 1266], 31: [1096, 750, 3030, 949, 918], 32: [750, 3030, 933, 3983, 68237], 33: [3030, 7028, 5500, 104879, 933], 34: [918, 1096, 3983, 3030, 933], 35: [750, 3030, 5500, 1103, 1096], 36: [1096, 1274, 3030, 5500, 2730], 37: [918, 750, 1274, 1921, 5500], 38: [3030, 1096, 104879, 3983, 1266], 39: [918, 750, 1096, 3030, 5500], 40: [918, 750, 3030, 3983, 5500], 41: [3030, 5500, 918, 5339, 933], 42: [3030, 750, 1096, 3983, 5500], 43: [1096, 3030, 5500, 2730, 949], 44: [3030, 5339, 1096, 5500, 7028], 45: [933, 918, 5500, 106766, 2730], 46: [5500, 933, 1967, 356, 1921], 47: [4821, 1096, 6832, 1921, 5500], 48: [1096, 949, 2730, 918, 3030], 49: [356, 918, 3030, 1274, 750], 50: [3030, 1096, 5500, 1274, 2730], 51: [1096, 3030, 918, 1921, 5500], 52: [5500, 949, 3030, 1266, 356], 53: [1103, 933, 1096, 104879, 158872], 54: [2730, 5500, 1921, 750, 104879], 55: [3030, 5500, 933, 1653, 750], 56: [1096, 3030, 3983, 5500, 933], 57: [3030, 5500, 104879, 750, 933], 58: [918, 3983, 5500, 3030, 1096], 59: [3030, 1096, 34405, 1704, 1274], 60: [1096, 918, 949, 5500, 3030]}\n"
     ]
    }
   ],
   "source": [
    "def group_aggregation(predicted_ratings, groups, num_items=5):\n",
    "    group_recommendations = {}\n",
    "\n",
    "    for i, group in enumerate(groups):\n",
    "        # Filter the predictions for users in the current group\n",
    "        group_predictions = predicted_ratings[predicted_ratings['user'].isin(group)]\n",
    "\n",
    "        # Calculate average satisfaction score for each item\n",
    "        avg_satisfaction = group_predictions.groupby('item')['predicted_rating'].mean()\n",
    "\n",
    "        # Select top 'num_items' items based on average satisfaction\n",
    "        top_items = avg_satisfaction.nlargest(num_items).index.tolist()\n",
    "\n",
    "        # Store the recommendations for the group\n",
    "        group_recommendations[i] = top_items\n",
    "\n",
    "    return group_recommendations\n",
    "\n",
    "# Create the group recommendations for all different group sizes\n",
    "group_recommendations2 = group_aggregation(predicted_ratings2, test_groups2)\n",
    "group_recommendations3 = group_aggregation(predicted_ratings3, test_groups3)\n",
    "group_recommendations5 = group_aggregation(predicted_ratings5, test_groups5)\n",
    "# Print the recommendations of group size 2 for visualisation\n",
    "print(group_recommendations2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average nDCG for all groups of size 2: 0.7664324604005274\n",
      "Average nDCG for all groups of size 3: 0.8123768153032932\n",
      "Average nDCG for all groups of size 5: 0.6990185352457589\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ndcg(recommended_items, relevance_scores, k=5):\n",
    "    # Convert relevance_scores to array if it's not already\n",
    "    relevance_scores = np.array(relevance_scores)\n",
    "        \n",
    "    # Compute DCG\n",
    "    dcg = relevance_scores[0] + np.sum(relevance_scores[1:] / np.log2(np.arange(2, relevance_scores.size + 1)))\n",
    "\n",
    "    # Compute IDCG\n",
    "    ideal_relevance_scores = np.sort(relevance_scores)[::-1]\n",
    "    idcg = ideal_relevance_scores[0] + np.sum(ideal_relevance_scores[1:] / np.log2(np.arange(2, ideal_relevance_scores.size + 1)))\n",
    "\n",
    "    # nDCG\n",
    "    return dcg / idcg if idcg > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_groups(predicted_ratings_df, groups, group_recommendations):\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for idx, group in enumerate(groups):\n",
    "        # Get all predicted ratings for items recommended to the group members\n",
    "        group_pred_ratings = predicted_ratings_df[predicted_ratings_df['user'].isin(group)]\n",
    "        \n",
    "        # Create a dictionary from the item-predicted_rating pairs for easy lookup\n",
    "        item_rating_dict = dict(zip(group_pred_ratings['item'], group_pred_ratings['predicted_rating']))\n",
    "\n",
    "        # Get the list of recommendations for the current group using the group index\n",
    "        recommendations = group_recommendations[idx]\n",
    "\n",
    "        # Create the relevance scores list for the recommended items for this group\n",
    "        relevance_scores = [item_rating_dict.get(item, 0) for item in recommendations]\n",
    "\n",
    "        # Compute nDCG for the group and append to the list\n",
    "        group_ndcg = ndcg(recommendations, relevance_scores)\n",
    "        ndcg_scores.append(group_ndcg)\n",
    "\n",
    "    # Average nDCG across all groups\n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "    return avg_ndcg\n",
    "\n",
    "# Convert group_recommendations from dictionary to list of lists if necessary\n",
    "group_recommendations_list2 = list(group_recommendations2.values())\n",
    "average_ndcg = evaluate_groups(predicted_ratings2, test_groups2, group_recommendations_list2)\n",
    "print(f\"Average nDCG for all groups of size 2: {average_ndcg}\")\n",
    "\n",
    "group_recommendations_list3 = list(group_recommendations2.values())\n",
    "average_ndcg = evaluate_groups(predicted_ratings3, test_groups3, group_recommendations_list3)\n",
    "print(f\"Average nDCG for all groups of size 3: {average_ndcg}\")\n",
    "\n",
    "group_recommendations_list5 = list(group_recommendations2.values())\n",
    "average_ndcg = evaluate_groups(predicted_ratings5, test_groups5, group_recommendations_list5)\n",
    "print(f\"Average nDCG for all groups of size 5: {average_ndcg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs= 1000\n",
    "def run_everythin(runs,n):\n",
    "    all_ndcg_scores = []\n",
    "    for run in range(runs):\n",
    "        train_users, test_users = split_users((1, 610))\n",
    "        train_groups = generate_groups(train_users, n)\n",
    "        test_groups2 = generate_groups(test_users, 2)\n",
    "        train_set = user_item_interactions(ratings_df,train_users)  \n",
    "        test_i2 = user_item_interactions(ratings_df,test_groups2)\n",
    "\n",
    "    return all_ndcg_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
